{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append('../pp_1st')\n",
    "sys.path.append('../pp_2nd')\n",
    "import pp2nd_func\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (8,172,173,174,175,176,177,178,179) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('../raw/PJT002_train.csv', )\n",
    "val = pd.read_csv('../raw/PJT002_validation.csv' )\n",
    "test = pd.read_csv('../raw/PJT002_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_y = {'N': 0, 'Y': 1}\n",
    "train['fr_yn'] = train['fr_yn'].map(binary_y)\n",
    "val['fr_yn'] = val['fr_yn'].map(binary_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[\"bldng_us\"].values == \"제1종근린생활시설\", \"bldng_us\"] = None\n",
    "train.loc[train[\"bldng_us\"].values == \"제2종근린생활시설\", \"bldng_us\"] = None\n",
    "\n",
    "val.loc[val[\"bldng_us\"].values == \"제1종근린생활시설\", \"bldng_us\"] = None\n",
    "val.loc[val[\"bldng_us\"].values == \"제2종근린생활시설\", \"bldng_us\"] = None\n",
    "\n",
    "test.loc[test[\"bldng_us\"].values == \"제1종근린생활시설\", \"bldng_us\"] = None\n",
    "test.loc[test[\"bldng_us\"].values == \"제2종근린생활시설\", \"bldng_us\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_bldng_us = pd.get_dummies(train[\"bldng_us\"])\n",
    "train = train.join(one_hot_bldng_us)\n",
    "\n",
    "one_hot_bldng_us = pd.get_dummies(val[\"bldng_us\"])\n",
    "val = val.join(one_hot_bldng_us)\n",
    "\n",
    "one_hot_bldng_us = pd.get_dummies(test[\"bldng_us\"])\n",
    "test = test.join(one_hot_bldng_us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [\"목구조\", \"일반목구조\", \"벽돌구조\", \"블록구조\", \"석구조\", \"조적구조\"]\n",
    "B = [\"강파이프구조\", \"경량철골구조\", \"기타강구조\", \"기타구조\", \"기타조적구조\"]\n",
    "C = [\"일반철골구조\", \"철골철근콘크리트구조\", \"철골콘크리트구조\", \"철근콘크리트구조\"]\n",
    "\n",
    "for i in A:\n",
    "    train.loc[train[\"bldng_archtctr\"].values == i, \"bldng_archtctr_encoded\"] = \"A\"\n",
    "\n",
    "for i in B:\n",
    "    train.loc[train[\"bldng_archtctr\"].values == i, \"bldng_archtctr_encoded\"] = \"B\"\n",
    "    \n",
    "for i in C:\n",
    "    train.loc[train[\"bldng_archtctr\"].values == i, \"bldng_archtctr_encoded\"] = \"C\"\n",
    "\n",
    "    \n",
    "for i in A:\n",
    "    val.loc[val[\"bldng_archtctr\"].values == i, \"bldng_archtctr_encoded\"] = \"A\"\n",
    "\n",
    "for i in B:\n",
    "    val.loc[val[\"bldng_archtctr\"].values == i, \"bldng_archtctr_encoded\"] = \"B\"\n",
    "    \n",
    "for i in C:\n",
    "    val.loc[val[\"bldng_archtctr\"].values == i, \"bldng_archtctr_encoded\"] = \"C\"\n",
    "\n",
    "\n",
    "for i in A:\n",
    "    test.loc[test[\"bldng_archtctr\"].values == i, \"bldng_archtctr_encoded\"] = \"A\"\n",
    "\n",
    "for i in B:\n",
    "    test.loc[test[\"bldng_archtctr\"].values == i, \"bldng_archtctr_encoded\"] = \"B\"\n",
    "    \n",
    "for i in C:\n",
    "    test.loc[test[\"bldng_archtctr\"].values == i, \"bldng_archtctr_encoded\"] = \"C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_bldng_archtctr = pd.get_dummies(train[\"bldng_archtctr_encoded\"])\n",
    "train = train.join(one_hot_bldng_archtctr)\n",
    "\n",
    "one_hot_bldng_archtctr = pd.get_dummies(val[\"bldng_archtctr_encoded\"])\n",
    "val = val.join(one_hot_bldng_archtctr)\n",
    "\n",
    "one_hot_bldng_archtctr = pd.get_dummies(test[\"bldng_archtctr_encoded\"])\n",
    "test = test.join(one_hot_bldng_archtctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(\"bldng_archtctr\", 1)\n",
    "val = val.drop(\"bldng_archtctr\", 1)\n",
    "test = test.drop(\"bldng_archtctr\", 1)\n",
    "\n",
    "train = train.drop(\"bldng_archtctr_encoded\", 1)\n",
    "val = val.drop(\"bldng_archtctr_encoded\", 1)\n",
    "test = test.drop(\"bldng_archtctr_encoded\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[\"bldng_ar\"]==0, \"bldng_ar\"] = train[\"bldng_ar\"].median()\n",
    "train.loc[train[\"ttl_ar\"]==0, \"ttl_ar\"] = train[\"ttl_ar\"].median()\n",
    "\n",
    "val.loc[val[\"bldng_ar\"]==0, \"bldng_ar\"] = val[\"bldng_ar\"].median()\n",
    "val.loc[val[\"ttl_ar\"]==0, \"ttl_ar\"] = val[\"ttl_ar\"].median()\n",
    "\n",
    "test.loc[test[\"bldng_ar\"]==0, \"bldng_ar\"] = test[\"bldng_ar\"].median()\n",
    "test.loc[test[\"ttl_ar\"]==0, \"ttl_ar\"] = test[\"ttl_ar\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(\"lnd_ar\", 1)\n",
    "val = val.drop(\"lnd_ar\", 1)\n",
    "test = test.drop(\"lnd_ar\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[32635, 'dt_of_athrztn'] = 20020227 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"dt_of_athrztn\"] = train[\"dt_of_athrztn\"].astype(str)\n",
    "val[\"dt_of_athrztn\"] = val[\"dt_of_athrztn\"].astype(str)\n",
    "test[\"dt_of_athrztn\"]=test[\"dt_of_athrztn\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"year_athrztn\"] = train[\"dt_of_athrztn\"].apply(lambda x : x[:4])\n",
    "val[\"year_athrztn\"] = val[\"dt_of_athrztn\"].apply(lambda x : x[:4])\n",
    "test[\"year_athrztn\"]=test[\"dt_of_athrztn\"].apply(lambda x : x[:4])\n",
    "\n",
    "year_athrztn_notnull = train[(train[\"year_athrztn\"]!=\"nan\")]\n",
    "year_athrztn_YYYY = year_athrztn_notnull[year_athrztn_notnull[\"year_athrztn\"].astype(int)<3000]\n",
    "year_athrztn_YY = year_athrztn_notnull[year_athrztn_notnull[\"year_athrztn\"].astype(int)>3000]\n",
    "year_athrztn_null = train[train[\"year_athrztn\"]==\"nan\"]\n",
    "\n",
    "year_athrztn_YY[\"year_athrztn\"] = 1900 + year_athrztn_YY[\"dt_of_athrztn\"].str[:2].astype(int)\n",
    "year_athrztn_notnull = year_athrztn_YYYY.append(year_athrztn_YY)\n",
    "year_athrztn_median=year_athrztn_notnull[\"year_athrztn\"].median()\n",
    "year_athrztn_null[\"year_athrztn\"]=year_athrztn_median\n",
    "\n",
    "train = year_athrztn_notnull.append(year_athrztn_null)\n",
    "val.loc[val[\"year_athrztn\"]==\"nan\",\"year_athrztn\"]= val[val[\"year_athrztn\"]!=\"nan\"][\"year_athrztn\"].median()\n",
    "test.loc[test[\"year_athrztn\"]==\"nan\",\"year_athrztn\"]= test[test[\"year_athrztn\"]!=\"nan\"][\"year_athrztn\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train[\"year_athrztn\"] = train[\"year_athrztn\"].astype(float).astype(int)\n",
    "val[\"year_athrztn\"] = val[\"year_athrztn\"].astype(float).astype(int)\n",
    "test[\"year_athrztn\"]=test[\"year_athrztn\"].astype(float).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[\"year_athrztn\"]<2000,\"year_athrztn_encoded\"] = \"old\"\n",
    "train.loc[train[\"year_athrztn\"]>1999,\"year_athrztn_encoded\"] = \"new\"\n",
    "\n",
    "val.loc[val[\"year_athrztn\"]<2000,\"year_athrztn_encoded\"] = \"old\"\n",
    "val.loc[val[\"year_athrztn\"]>1999,\"year_athrztn_encoded\"] = \"new\"\n",
    "\n",
    "test.loc[test[\"year_athrztn\"]<2000,\"year_athrztn_encoded\"] = \"old\"\n",
    "test.loc[test[\"year_athrztn\"]>1999,\"year_athrztn_encoded\"] = \"new\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fr_yn</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year_athrztn_encoded</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>0.300941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>old</th>\n",
       "      <td>0.093631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         fr_yn\n",
       "year_athrztn_encoded          \n",
       "new                   0.300941\n",
       "old                   0.093631"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot_table(train, index=\"year_athrztn_encoded\", values=\"fr_yn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(\"dt_of_athrztn\", 1)\n",
    "val = val.drop(\"dt_of_athrztn\", 1)\n",
    "test = test.drop(\"dt_of_athrztn\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train.loc[train[\"trgt_crtr\"]==\"자동화재탐지설치대상\", \"auto_fr\"] = 1\n",
    "train.loc[train[\"trgt_crtr\"]!=\"자동화재탐지설치대상\", \"auto_fr\"] = 0\n",
    "train.loc[train[\"trgt_crtr\"]==\"옥내소화전설치대상\", \"fireplug\"] = 1\n",
    "train.loc[train[\"trgt_crtr\"]!=\"옥내소화전설치대상\", \"fireplug\"] = 0\n",
    "train.loc[train[\"trgt_crtr\"]==\"스프링클러,물분무등설치대상\", \"sprinkler\"] = 1\n",
    "train.loc[train[\"trgt_crtr\"]!=\"스프링클러,물분무등설치대상\", \"sprinkler\"] = 0\n",
    "\n",
    "\n",
    "val.loc[val[\"trgt_crtr\"]==\"자동화재탐지설치대상\", \"auto_fr\"] = 1\n",
    "val.loc[val[\"trgt_crtr\"]!=\"자동화재탐지설치대상\", \"auto_fr\"] = 0\n",
    "val.loc[val[\"trgt_crtr\"]==\"옥내소화전설치대상\", \"fireplug\"] = 1\n",
    "val.loc[val[\"trgt_crtr\"]!=\"옥내소화전설치대상\", \"fireplug\"] = 0\n",
    "val.loc[val[\"trgt_crtr\"]==\"스프링클러,물분무등설치대상\", \"sprinkler\"] = 1\n",
    "val.loc[val[\"trgt_crtr\"]!=\"스프링클러,물분무등설치대상\", \"sprinkler\"] = 0\n",
    "\n",
    "test.loc[test[\"trgt_crtr\"]==\"자동화재탐지설치대상\", \"auto_fr\"] = 1\n",
    "test.loc[test[\"trgt_crtr\"]!=\"자동화재탐지설치대상\", \"auto_fr\"] = 0\n",
    "test.loc[test[\"trgt_crtr\"]==\"옥내소화전설치대상\", \"fireplug\"] = 1\n",
    "test.loc[test[\"trgt_crtr\"]!=\"옥내소화전설치대상\", \"fireplug\"] = 0\n",
    "test.loc[test[\"trgt_crtr\"]==\"스프링클러,물분무등설치대상\", \"sprinkler\"] = 1\n",
    "test.loc[test[\"trgt_crtr\"]!=\"스프링클러,물분무등설치대상\", \"sprinkler\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = train.drop(\"trgt_crtr\", 1)\n",
    "val = val.drop(\"trgt_crtr\", 1)\n",
    "test = test.drop(\"trgt_crtr\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.loc[train[\"fr_fghtng_fclt_spcl_css_5_yn\"].isnull(),\"css_5_yn_encoded\"]=0\n",
    "# train.loc[train[\"fr_fghtng_fclt_spcl_css_5_yn\"].notnull(),\"css_5_yn_encoded\"]=1\n",
    "\n",
    "train.loc[train[\"fr_fghtng_fclt_spcl_css_6_yn\"].isnull(),\"css_6_yn_encoded\"]=0\n",
    "train.loc[train[\"fr_fghtng_fclt_spcl_css_6_yn\"].notnull(),\"css_6_yn_encoded\"]=1\n",
    "\n",
    "val.loc[train[\"fr_fghtng_fclt_spcl_css_6_yn\"].isnull(),\"css_6_yn_encoded\"]=0\n",
    "val.loc[train[\"fr_fghtng_fclt_spcl_css_6_yn\"].notnull(),\"css_6_yn_encoded\"]=1\n",
    "\n",
    "test.loc[train[\"fr_fghtng_fclt_spcl_css_6_yn\"].isnull(),\"css_6_yn_encoded\"]=0\n",
    "test.loc[train[\"fr_fghtng_fclt_spcl_css_6_yn\"].notnull(),\"css_6_yn_encoded\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(\"fr_fghtng_fclt_spcl_css_5_yn\", 1)\n",
    "val = val.drop(\"fr_fghtng_fclt_spcl_css_5_yn\", 1)\n",
    "test = test.drop(\"fr_fghtng_fclt_spcl_css_5_yn\", 1)\n",
    "\n",
    "train = train.drop(\"fr_fghtng_fclt_spcl_css_6_yn\", 1)\n",
    "val = val.drop(\"fr_fghtng_fclt_spcl_css_6_yn\", 1)\n",
    "test = test.drop(\"fr_fghtng_fclt_spcl_css_6_yn\", 1)\n",
    "\n",
    "train = train.drop(\"css_5_yn_encoded\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_us_yn = pd.get_dummies(train[\"us_yn\"])\n",
    "train = train.join(one_hot_us_yn)\n",
    "\n",
    "one_hot_us_yn = pd.get_dummies(val[\"us_yn\"])\n",
    "val = val.join(one_hot_us_yn)\n",
    "\n",
    "one_hot_us_yn = pd.get_dummies(test[\"us_yn\"])\n",
    "test = test.join(one_hot_us_yn)\n",
    "\n",
    "train = train.drop(\"us_yn\", 1)\n",
    "val = val.drop(\"us_yn\", 1)\n",
    "test = test.drop(\"us_yn\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[\"dngrs_thng_yn\"].isnull(),\"dngrs_thng_yn_encoded\"]= 0\n",
    "train.loc[train[\"dngrs_thng_yn\"].notnull(),\"dngrs_thng_yn_encoded\"]= 1\n",
    "val.loc[train[\"dngrs_thng_yn\"].isnull(),\"dngrs_thng_yn_encoded\"]= 0\n",
    "val.loc[train[\"dngrs_thng_yn\"].notnull(),\"dngrs_thng_yn_encoded\"]= 1\n",
    "\n",
    "test.loc[train[\"dngrs_thng_yn\"].isnull(),\"dngrs_thng_yn_encoded\"]= 0\n",
    "test.loc[train[\"dngrs_thng_yn\"].notnull(),\"dngrs_thng_yn_encoded\"]= 1\n",
    "\n",
    "train = train.drop(\"dngrs_thng_yn\", 1)\n",
    "val = val.drop(\"dngrs_thng_yn\", 1)\n",
    "test = test.drop(\"dngrs_thng_yn\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[\"slf_fr_brgd_yn\"].isnull(),\"slf_fr_brgd_yn\"]=0\n",
    "train = train.drop(\"slf_fr_brgd_yn\", 1)\n",
    "val = val.drop(\"slf_fr_brgd_yn\", 1)\n",
    "test = test.drop(\"slf_fr_brgd_yn\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train[\"blk_dngrs_thng_mnfctr_yn\"].isnull(),\"blk_dngrs_thng_mnfctr_yn\"]=0\n",
    "train = train.drop(\"blk_dngrs_thng_mnfctr_yn\", 1)\n",
    "val = val.drop(\"blk_dngrs_thng_mnfctr_yn\", 1)\n",
    "test = test.drop(\"blk_dngrs_thng_mnfctr_yn\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(\"cltrl_hrtg_yn\", 1)\n",
    "val = val.drop(\"cltrl_hrtg_yn\", 1)\n",
    "test = test.drop(\"cltrl_hrtg_yn\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['fr_yn', 'dt_of_fr'], 1)\n",
    "y_train = train['fr_yn']\n",
    "X_val = val.drop(['fr_yn', 'dt_of_fr'], 1)\n",
    "y_val = val['fr_yn']\n",
    "test = test.drop(['dt_of_fr'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.concat([X_train, X_val, test])\n",
    "\n",
    "categorical_cols = df_all.select_dtypes(['object']).columns\n",
    "for col in categorical_cols:\n",
    "    df_all[col] = pd.Categorical(df_all[col]).codes\n",
    "\n",
    "X_train = df_all[:len(train)]\n",
    "X_val = df_all[len(train):-len(test)]\n",
    "test = df_all[-len(test):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X_train.fillna(-1)\n",
    "X_val = X_val.fillna(-1)\n",
    "test = test.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5052454888795636"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_ = RandomForestClassifier(n_jobs=-1, n_estimators=100, random_state=42)\n",
    "rf_.fit(X_train, y_train)\n",
    "y_pred = rf_.predict(X_val)\n",
    "f1_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_rf = rf_.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_rf  = np.argmax(yhat_rf,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import *\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras import *\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47359 samples, validate on 11840 samples\n",
      "Epoch 1/100\n",
      "47359/47359 [==============================] - 25s 518us/step - loss: 0.4769 - acc: 0.8117 - val_loss: 0.1769 - val_acc: 1.0000\n",
      "Epoch 2/100\n",
      "47359/47359 [==============================] - 22s 469us/step - loss: 0.4142 - acc: 0.8404 - val_loss: 0.1791 - val_acc: 1.0000\n",
      "Epoch 3/100\n",
      "47359/47359 [==============================] - 22s 464us/step - loss: 0.4032 - acc: 0.8421 - val_loss: 0.1450 - val_acc: 1.0000\n",
      "Epoch 4/100\n",
      "47359/47359 [==============================] - 22s 465us/step - loss: 0.3981 - acc: 0.8420 - val_loss: 0.1404 - val_acc: 1.0000\n",
      "Epoch 5/100\n",
      "47359/47359 [==============================] - 22s 469us/step - loss: 0.3944 - acc: 0.8416 - val_loss: 0.1453 - val_acc: 1.0000\n",
      "Epoch 6/100\n",
      "47359/47359 [==============================] - 22s 472us/step - loss: 0.3923 - acc: 0.8441 - val_loss: 0.1308 - val_acc: 1.0000\n",
      "Epoch 7/100\n",
      "47359/47359 [==============================] - 22s 463us/step - loss: 0.3908 - acc: 0.8433 - val_loss: 0.1267 - val_acc: 1.0000\n",
      "Epoch 8/100\n",
      "47359/47359 [==============================] - 23s 475us/step - loss: 0.3899 - acc: 0.8440 - val_loss: 0.1337 - val_acc: 1.0000\n",
      "Epoch 9/100\n",
      "47359/47359 [==============================] - 22s 468us/step - loss: 0.3908 - acc: 0.8417 - val_loss: 0.1360 - val_acc: 1.0000\n",
      "Epoch 10/100\n",
      "47359/47359 [==============================] - 22s 473us/step - loss: 0.3896 - acc: 0.8433 - val_loss: 0.1377 - val_acc: 0.9999\n",
      "Epoch 11/100\n",
      "47359/47359 [==============================] - 22s 468us/step - loss: 0.3874 - acc: 0.8441 - val_loss: 0.1345 - val_acc: 1.0000\n",
      "Epoch 12/100\n",
      "47359/47359 [==============================] - 22s 473us/step - loss: 0.3857 - acc: 0.8435 - val_loss: 0.1423 - val_acc: 1.0000\n",
      "Epoch 13/100\n",
      "47359/47359 [==============================] - 22s 469us/step - loss: 0.3867 - acc: 0.8442 - val_loss: 0.1270 - val_acc: 1.0000\n",
      "Epoch 14/100\n",
      "47359/47359 [==============================] - 22s 463us/step - loss: 0.3866 - acc: 0.8451 - val_loss: 0.1512 - val_acc: 1.0000\n",
      "Epoch 15/100\n",
      "47359/47359 [==============================] - 22s 461us/step - loss: 0.3862 - acc: 0.8437 - val_loss: 0.1172 - val_acc: 0.9999\n",
      "Epoch 16/100\n",
      "47359/47359 [==============================] - 22s 472us/step - loss: 0.3850 - acc: 0.8453 - val_loss: 0.1340 - val_acc: 0.9999\n",
      "Epoch 17/100\n",
      "47359/47359 [==============================] - 22s 472us/step - loss: 0.3850 - acc: 0.8451 - val_loss: 0.1461 - val_acc: 1.0000\n",
      "Epoch 18/100\n",
      "47359/47359 [==============================] - 23s 477us/step - loss: 0.3833 - acc: 0.8456 - val_loss: 0.1653 - val_acc: 1.0000\n",
      "Epoch 19/100\n",
      "47359/47359 [==============================] - 22s 473us/step - loss: 0.3859 - acc: 0.8456 - val_loss: 0.1479 - val_acc: 1.0000\n",
      "Epoch 20/100\n",
      "47359/47359 [==============================] - 22s 474us/step - loss: 0.3841 - acc: 0.8454 - val_loss: 0.1395 - val_acc: 1.0000\n",
      "Epoch 21/100\n",
      "47359/47359 [==============================] - 22s 464us/step - loss: 0.3838 - acc: 0.8462 - val_loss: 0.1230 - val_acc: 1.0000\n",
      "Epoch 22/100\n",
      "47359/47359 [==============================] - 22s 474us/step - loss: 0.3850 - acc: 0.8450 - val_loss: 0.1391 - val_acc: 0.9997\n",
      "Epoch 23/100\n",
      "47359/47359 [==============================] - 22s 472us/step - loss: 0.3847 - acc: 0.8459 - val_loss: 0.1298 - val_acc: 1.0000\n",
      "Epoch 24/100\n",
      "47359/47359 [==============================] - 23s 476us/step - loss: 0.3827 - acc: 0.8455 - val_loss: 0.1400 - val_acc: 1.0000\n",
      "Epoch 25/100\n",
      "47359/47359 [==============================] - 22s 471us/step - loss: 0.3826 - acc: 0.8455 - val_loss: 0.1274 - val_acc: 1.0000\n",
      "Epoch 26/100\n",
      "47359/47359 [==============================] - 22s 471us/step - loss: 0.3832 - acc: 0.8454 - val_loss: 0.1197 - val_acc: 0.9997\n",
      "Epoch 27/100\n",
      "47359/47359 [==============================] - 22s 469us/step - loss: 0.3823 - acc: 0.8460 - val_loss: 0.1296 - val_acc: 1.0000\n",
      "Epoch 28/100\n",
      "47359/47359 [==============================] - 22s 471us/step - loss: 0.3817 - acc: 0.8462 - val_loss: 0.1348 - val_acc: 1.0000\n",
      "Epoch 29/100\n",
      "47359/47359 [==============================] - 22s 473us/step - loss: 0.3810 - acc: 0.8470 - val_loss: 0.1237 - val_acc: 1.0000\n",
      "Epoch 30/100\n",
      "47359/47359 [==============================] - 22s 474us/step - loss: 0.3817 - acc: 0.8462 - val_loss: 0.1266 - val_acc: 1.0000\n",
      "Epoch 31/100\n",
      "47359/47359 [==============================] - 22s 474us/step - loss: 0.3796 - acc: 0.8483 - val_loss: 0.1081 - val_acc: 1.0000\n",
      "Epoch 32/100\n",
      "47359/47359 [==============================] - 23s 478us/step - loss: 0.3802 - acc: 0.8484 - val_loss: 0.1274 - val_acc: 1.0000\n",
      "Epoch 33/100\n",
      "47359/47359 [==============================] - 23s 478us/step - loss: 0.3802 - acc: 0.8471 - val_loss: 0.1352 - val_acc: 1.0000\n",
      "Epoch 34/100\n",
      "47359/47359 [==============================] - 23s 478us/step - loss: 0.3794 - acc: 0.8479 - val_loss: 0.1288 - val_acc: 1.0000\n",
      "Epoch 35/100\n",
      "47359/47359 [==============================] - 22s 473us/step - loss: 0.3818 - acc: 0.8478 - val_loss: 0.1564 - val_acc: 1.0000\n",
      "Epoch 36/100\n",
      "47359/47359 [==============================] - 22s 471us/step - loss: 0.3805 - acc: 0.8463 - val_loss: 0.1107 - val_acc: 1.0000\n",
      "Epoch 37/100\n",
      "47359/47359 [==============================] - 22s 474us/step - loss: 0.3786 - acc: 0.8484 - val_loss: 0.1254 - val_acc: 1.0000\n",
      "Epoch 38/100\n",
      "47359/47359 [==============================] - 22s 467us/step - loss: 0.3798 - acc: 0.8476 - val_loss: 0.1377 - val_acc: 1.0000\n",
      "Epoch 39/100\n",
      "47359/47359 [==============================] - 22s 468us/step - loss: 0.3819 - acc: 0.8458 - val_loss: 0.0947 - val_acc: 1.0000\n",
      "Epoch 40/100\n",
      "47359/47359 [==============================] - 23s 479us/step - loss: 0.3792 - acc: 0.8476 - val_loss: 0.1356 - val_acc: 0.9997\n",
      "Epoch 41/100\n",
      "47359/47359 [==============================] - 22s 467us/step - loss: 0.3797 - acc: 0.8454 - val_loss: 0.1431 - val_acc: 0.9996\n",
      "Epoch 42/100\n",
      "47359/47359 [==============================] - 22s 470us/step - loss: 0.3818 - acc: 0.8471 - val_loss: 0.1136 - val_acc: 0.9993\n",
      "Epoch 43/100\n",
      "47359/47359 [==============================] - 23s 480us/step - loss: 0.3795 - acc: 0.8472 - val_loss: 0.1140 - val_acc: 1.0000\n",
      "Epoch 44/100\n",
      "47359/47359 [==============================] - 21s 440us/step - loss: 0.3799 - acc: 0.8470 - val_loss: 0.1341 - val_acc: 0.9999\n",
      "Epoch 45/100\n",
      "47359/47359 [==============================] - 22s 471us/step - loss: 0.3786 - acc: 0.8476 - val_loss: 0.1161 - val_acc: 1.0000\n",
      "Epoch 46/100\n",
      "47359/47359 [==============================] - 22s 468us/step - loss: 0.3794 - acc: 0.8471 - val_loss: 0.1367 - val_acc: 1.0000\n",
      "Epoch 47/100\n",
      "47359/47359 [==============================] - 23s 475us/step - loss: 0.3796 - acc: 0.8476 - val_loss: 0.1060 - val_acc: 1.0000\n",
      "Epoch 48/100\n",
      "47359/47359 [==============================] - 22s 471us/step - loss: 0.3778 - acc: 0.8492 - val_loss: 0.1018 - val_acc: 1.0000\n",
      "Epoch 49/100\n",
      "47359/47359 [==============================] - 23s 478us/step - loss: 0.3778 - acc: 0.8477 - val_loss: 0.1501 - val_acc: 1.0000\n",
      "Epoch 50/100\n",
      "47359/47359 [==============================] - 22s 471us/step - loss: 0.3792 - acc: 0.8478 - val_loss: 0.1189 - val_acc: 1.0000\n",
      "Epoch 51/100\n",
      "47359/47359 [==============================] - 22s 472us/step - loss: 0.3764 - acc: 0.8483 - val_loss: 0.1420 - val_acc: 1.0000\n",
      "Epoch 52/100\n",
      "47359/47359 [==============================] - 23s 476us/step - loss: 0.3771 - acc: 0.8482 - val_loss: 0.1344 - val_acc: 1.0000\n",
      "Epoch 53/100\n",
      "47359/47359 [==============================] - 23s 478us/step - loss: 0.3769 - acc: 0.8487 - val_loss: 0.1426 - val_acc: 1.0000\n",
      "Epoch 54/100\n",
      "47359/47359 [==============================] - 22s 468us/step - loss: 0.3765 - acc: 0.8477 - val_loss: 0.1339 - val_acc: 1.0000\n",
      "Epoch 55/100\n",
      "47359/47359 [==============================] - 22s 470us/step - loss: 0.3784 - acc: 0.8476 - val_loss: 0.1658 - val_acc: 1.0000\n",
      "Epoch 56/100\n",
      "47359/47359 [==============================] - 23s 477us/step - loss: 0.3770 - acc: 0.8478 - val_loss: 0.1317 - val_acc: 1.0000\n",
      "Epoch 57/100\n",
      "47359/47359 [==============================] - 23s 476us/step - loss: 0.3762 - acc: 0.8495 - val_loss: 0.1497 - val_acc: 1.0000\n",
      "Epoch 58/100\n",
      "47359/47359 [==============================] - 22s 475us/step - loss: 0.3772 - acc: 0.8464 - val_loss: 0.1722 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "47359/47359 [==============================] - 23s 476us/step - loss: 0.3770 - acc: 0.8484 - val_loss: 0.1517 - val_acc: 1.0000\n",
      "Epoch 60/100\n",
      "47359/47359 [==============================] - 22s 471us/step - loss: 0.3768 - acc: 0.8478 - val_loss: 0.1270 - val_acc: 1.0000\n",
      "Epoch 61/100\n",
      "47359/47359 [==============================] - 22s 473us/step - loss: 0.3760 - acc: 0.8478 - val_loss: 0.1565 - val_acc: 1.0000\n",
      "Epoch 62/100\n",
      "47359/47359 [==============================] - 22s 469us/step - loss: 0.3786 - acc: 0.8485 - val_loss: 0.1319 - val_acc: 1.0000\n",
      "Epoch 63/100\n",
      "47359/47359 [==============================] - 22s 474us/step - loss: 0.3746 - acc: 0.8479 - val_loss: 0.1232 - val_acc: 1.0000\n",
      "Epoch 64/100\n",
      "47359/47359 [==============================] - 22s 471us/step - loss: 0.3754 - acc: 0.8485 - val_loss: 0.1220 - val_acc: 1.0000\n",
      "Epoch 65/100\n",
      "47359/47359 [==============================] - 22s 470us/step - loss: 0.3762 - acc: 0.8486 - val_loss: 0.1252 - val_acc: 1.0000\n",
      "Epoch 66/100\n",
      "47359/47359 [==============================] - 22s 471us/step - loss: 0.3760 - acc: 0.8480 - val_loss: 0.1456 - val_acc: 1.0000\n",
      "Epoch 67/100\n",
      "47359/47359 [==============================] - 23s 476us/step - loss: 0.3755 - acc: 0.8477 - val_loss: 0.1183 - val_acc: 1.0000\n",
      "Epoch 68/100\n",
      "47359/47359 [==============================] - 23s 477us/step - loss: 0.3750 - acc: 0.8496 - val_loss: 0.1372 - val_acc: 1.0000\n",
      "Epoch 69/100\n",
      "47359/47359 [==============================] - 22s 460us/step - loss: 0.3766 - acc: 0.8490 - val_loss: 0.1323 - val_acc: 1.0000\n",
      "Epoch 70/100\n",
      "47359/47359 [==============================] - 22s 454us/step - loss: 0.3766 - acc: 0.8483 - val_loss: 0.1547 - val_acc: 1.0000\n",
      "Epoch 71/100\n",
      "47359/47359 [==============================] - 22s 456us/step - loss: 0.3766 - acc: 0.8494 - val_loss: 0.1291 - val_acc: 1.0000\n",
      "Epoch 72/100\n",
      "47359/47359 [==============================] - 22s 467us/step - loss: 0.3757 - acc: 0.8485 - val_loss: 0.1336 - val_acc: 0.9996\n",
      "Epoch 73/100\n",
      "47359/47359 [==============================] - 22s 468us/step - loss: 0.3766 - acc: 0.8466 - val_loss: 0.1237 - val_acc: 1.0000\n",
      "Epoch 74/100\n",
      "47359/47359 [==============================] - 22s 471us/step - loss: 0.3779 - acc: 0.8475 - val_loss: 0.1407 - val_acc: 0.9998\n",
      "Epoch 75/100\n",
      "47359/47359 [==============================] - 22s 475us/step - loss: 0.3750 - acc: 0.8489 - val_loss: 0.1695 - val_acc: 1.0000\n",
      "Epoch 76/100\n",
      "47359/47359 [==============================] - 23s 475us/step - loss: 0.3766 - acc: 0.8488 - val_loss: 0.1372 - val_acc: 1.0000\n",
      "Epoch 77/100\n",
      "47359/47359 [==============================] - 22s 473us/step - loss: 0.3748 - acc: 0.8485 - val_loss: 0.1467 - val_acc: 0.9987\n",
      "Epoch 78/100\n",
      "47359/47359 [==============================] - 22s 474us/step - loss: 0.3768 - acc: 0.8474 - val_loss: 0.1180 - val_acc: 1.0000\n",
      "Epoch 79/100\n",
      "47359/47359 [==============================] - 22s 472us/step - loss: 0.3757 - acc: 0.8479 - val_loss: 0.1227 - val_acc: 1.0000\n",
      "Epoch 80/100\n",
      "47359/47359 [==============================] - 22s 466us/step - loss: 0.3762 - acc: 0.8485 - val_loss: 0.1729 - val_acc: 1.0000\n",
      "Epoch 81/100\n",
      "47359/47359 [==============================] - 22s 461us/step - loss: 0.3745 - acc: 0.8478 - val_loss: 0.1192 - val_acc: 1.0000\n",
      "Epoch 82/100\n",
      "47359/47359 [==============================] - 22s 462us/step - loss: 0.3758 - acc: 0.8482 - val_loss: 0.1420 - val_acc: 1.0000\n",
      "Epoch 83/100\n",
      "47359/47359 [==============================] - 22s 459us/step - loss: 0.3757 - acc: 0.8478 - val_loss: 0.1131 - val_acc: 1.0000\n",
      "Epoch 84/100\n",
      "47359/47359 [==============================] - 22s 468us/step - loss: 0.3756 - acc: 0.8494 - val_loss: 0.1182 - val_acc: 1.0000\n",
      "Epoch 85/100\n",
      "47359/47359 [==============================] - 22s 470us/step - loss: 0.3754 - acc: 0.8485 - val_loss: 0.1367 - val_acc: 1.0000\n",
      "Epoch 86/100\n",
      "47359/47359 [==============================] - 21s 439us/step - loss: 0.3751 - acc: 0.8492 - val_loss: 0.1859 - val_acc: 0.9992\n",
      "Epoch 87/100\n",
      "47359/47359 [==============================] - 23s 477us/step - loss: 0.3741 - acc: 0.8487 - val_loss: 0.1386 - val_acc: 0.9999\n",
      "Epoch 88/100\n",
      "47359/47359 [==============================] - 22s 465us/step - loss: 0.3759 - acc: 0.8478 - val_loss: 0.1329 - val_acc: 1.0000\n",
      "Epoch 89/100\n",
      "47359/47359 [==============================] - 22s 470us/step - loss: 0.3755 - acc: 0.8485 - val_loss: 0.1465 - val_acc: 1.0000\n",
      "Epoch 90/100\n",
      "47359/47359 [==============================] - 22s 465us/step - loss: 0.3744 - acc: 0.8479 - val_loss: 0.1471 - val_acc: 1.0000\n",
      "Epoch 91/100\n",
      "47359/47359 [==============================] - 22s 473us/step - loss: 0.3740 - acc: 0.8495 - val_loss: 0.1433 - val_acc: 1.0000\n",
      "Epoch 92/100\n",
      "47359/47359 [==============================] - 22s 455us/step - loss: 0.3728 - acc: 0.8486 - val_loss: 0.1711 - val_acc: 1.0000\n",
      "Epoch 93/100\n",
      "47359/47359 [==============================] - 22s 461us/step - loss: 0.3742 - acc: 0.8488 - val_loss: 0.1874 - val_acc: 0.9999\n",
      "Epoch 94/100\n",
      "47359/47359 [==============================] - 21s 453us/step - loss: 0.3733 - acc: 0.8487 - val_loss: 0.1850 - val_acc: 1.0000\n",
      "Epoch 95/100\n",
      "47359/47359 [==============================] - 21s 450us/step - loss: 0.3741 - acc: 0.8491 - val_loss: 0.1163 - val_acc: 1.0000\n",
      "Epoch 96/100\n",
      "47359/47359 [==============================] - 21s 442us/step - loss: 0.3751 - acc: 0.8485 - val_loss: 0.1439 - val_acc: 1.0000\n",
      "Epoch 97/100\n",
      "47359/47359 [==============================] - 22s 456us/step - loss: 0.3763 - acc: 0.8476 - val_loss: 0.1375 - val_acc: 0.9999\n",
      "Epoch 98/100\n",
      "47359/47359 [==============================] - 22s 456us/step - loss: 0.3735 - acc: 0.8489 - val_loss: 0.1346 - val_acc: 1.0000\n",
      "Epoch 99/100\n",
      "47359/47359 [==============================] - 20s 432us/step - loss: 0.3748 - acc: 0.8486 - val_loss: 0.1595 - val_acc: 1.0000\n",
      "Epoch 100/100\n",
      "47359/47359 [==============================] - 22s 469us/step - loss: 0.3727 - acc: 0.8483 - val_loss: 0.0962 - val_acc: 1.0000\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-cc51ffb0c686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m history = model.fit(np.asarray(X_train), np.asarray(y_train), validation_split=0.2, epochs=100, \n\u001b[1;32m     21\u001b[0m                     batch_size=32, verbose=1)\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n Test accuracy: %.4f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(18, activation='softplus'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(18, activation='selu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(np.asarray(X_train), np.asarray(y_train), validation_split=0.2, epochs=100, \n",
    "                    batch_size=32, verbose=1)\n",
    "print('\\n Test accuracy: %.4f' % (model.evaluate(X_test, y_test)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_res = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yhat_dnn = np.where(dnn_res > 0.2, 1, 0)\n",
    "yhat_dnn = np.ndarray.flatten(yhat_dnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score :  0.3968773608662805\n"
     ]
    }
   ],
   "source": [
    "# print('Accuracy : ',np.equal(test_y_, step_res).sum()/len(test_y_))\n",
    "print('F1 score : ',f1_score(y_val, yhat_dnn) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_dnn = np.ndarray.flatten(dnn_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_ = lgbm.LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
       "               random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_.fit(np.array(X_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_lgbm = lgbm_.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510460251046025"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, lgbm_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_lgbm = np.argmax(yhat_lgbm, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yhat_ensemble = 0.33*yhat_rf + 0.33*yhat_dnn + 0.33 * yhat_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_step = np.where(yhat_ensemble>0.15, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5142035239122619"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_val, ens_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
